{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e4270c-086b-4720-a802-9f08832c285c",
   "metadata": {},
   "source": [
    " # Multi Query Retrievers\n",
    "MultiVectorRetriever associates multiple vectors with a single document, useful for indexing document chunks and returning larger parent documents.\n",
    "\n",
    "ParentDocumentRetriever, a subclass of MultiVectorRetriever, includes convenience methods for populating a vector store to support this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e42ff1-c67e-46e4-a291-606c008f2f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5672f51-1ca8-4f60-8e07-f9948a7ea3c0",
   "metadata": {},
   "source": [
    " ## Step 1: Load Documents\n",
    " Here, we load the documents using `TextLoader`. You can replace the file paths\n",
    " with your own document paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12301cf8-9fbe-4f1c-802d-2d5f407a03bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73c5a541-1359-4a91-a783-e1b27f13545b",
   "metadata": {},
   "source": [
    " ## Step 2: Split Documents into Large Chunks\n",
    " Using `RecursiveCharacterTextSplitter`, we split documents into smaller chunks\n",
    " for more efficient processing and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dde2ed4-89d2-4cca-abf5-8ab6b8ecf59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "104c573e-f697-4d0c-babd-1a644ab89f55",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Step 3: Initialize the Vectorstore\n",
    " The vectorstore indexes the document chunks for similarity search. We use the `Chroma`\n",
    " library with embeddings from Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a12c03f-c7da-41eb-8b8c-7ffd93c5855b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6755b9eb-0f5b-4b82-94a2-ae4da717b9f5",
   "metadata": {},
   "source": [
    " ## Step 4: Create Smaller Chunks\n",
    " For fine-grained retrieval, we split the documents further into smaller chunks\n",
    " and associate metadata for linking with original documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c4eff4-9e45-455e-848a-8d838b922b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "854d9fb9-824a-41fe-b4b0-f75e49d7b02b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Step 5: Add Documents to Vectorstore\n",
    " Add the smaller chunks and their metadata to the vectorstore for similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b680ec2-0672-43ec-8608-2bd7de1fd2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f22bb2d2-e1b6-4ee7-aea6-b384ee283c54",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Step 6: Perform a Similarity Search\n",
    " Use the retriever to find documents similar to the query \"LangChain\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59881f72-e3db-4c88-8c5a-56ccae8ffc3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31458ef6-090b-421d-ae81-0779ea1e2f5e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Step 7: Multi-Modal Retrieval\n",
    " Modify the search type to use Maximal Marginal Relevance (MMR) for diverse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c34d97-635b-403c-9ce3-77316430cd61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d3370c4-a402-4a08-932a-7debe40afc32",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Step 8: Summarize Documents\n",
    " Associate summaries with documents using a language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17895d90-4ada-4f78-a4e4-5dfb93025c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09103003-a352-48ad-8e4e-77144b004366",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Step 9: Add Summaries to Vectorstore\n",
    " Store the summaries in the vectorstore for enhanced retrieval capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af8b5863-4267-48ee-9396-cc0968111b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "713fe068-a00d-42ad-9394-d3c0f4ccca03",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Step 10: Retrieve Summaries\n",
    " Perform a similarity search on the summaries to get the most relevant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de173c-6bb5-478c-b7f5-41373c930703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
