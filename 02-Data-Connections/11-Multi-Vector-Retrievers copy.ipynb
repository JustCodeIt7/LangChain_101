{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e4270c-086b-4720-a802-9f08832c285c",
   "metadata": {},
   "source": [
    " # Multi Query Retrievers\n",
    " This tutorial demonstrates how to build and use multi-query retrievers with LangChain.\n",
    " We'll start by loading documents, splitting them into chunks, and using embeddings\n",
    " to enable similarity search and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40e42ff1-c67e-46e4-a291-606c008f2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryByteStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from rich import print\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5672f51-1ca8-4f60-8e07-f9948a7ea3c0",
   "metadata": {},
   "source": [
    " ## Step 1: Load Documents\n",
    " Here, we load the documents using `TextLoader`. You can replace the file paths\n",
    " with your own document paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12301cf8-9fbe-4f1c-802d-2d5f407a03bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    TextLoader(\"data/langchain.md\"),\n",
    "    TextLoader(\"data/langchain2.md\"),\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c5a541-1359-4a91-a783-e1b27f13545b",
   "metadata": {},
   "source": [
    " ## Step 2: Split Documents into Large Chunks\n",
    " Using `RecursiveCharacterTextSplitter`, we split documents into smaller chunks\n",
    " for more efficient processing and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9dde2ed4-89d2-4cca-abf5-8ab6b8ecf59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n",
    "docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c573e-f697-4d0c-babd-1a644ab89f55",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Step 3: Initialize the Vectorstore\n",
    " The vectorstore indexes the document chunks for similarity search. We use the `Chroma`\n",
    " library with embeddings from Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a12c03f-c7da-41eb-8b8c-7ffd93c5855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(\n",
    "    collection_name=\"full_documents\",\n",
    "    embedding_function=OllamaEmbeddings(model='snowflake-arctic-embed:33m')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6755b9eb-0f5b-4b82-94a2-ae4da717b9f5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Step 4: Create Smaller Chunks\n",
    " For fine-grained retrieval, we split the documents further into smaller chunks\n",
    " and associate metadata for linking with original documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67c4eff4-9e45-455e-848a-8d838b922b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "# Initialize storage for parent documents\n",
    "store = InMemoryByteStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# Create the retriever\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "\n",
    "# Split into smaller chunks\n",
    "child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
    "sub_docs = []\n",
    "for i, doc in enumerate(docs):\n",
    "    _id = doc_ids[i]\n",
    "    _sub_docs = child_text_splitter.split_documents([doc])\n",
    "    for _doc in _sub_docs:\n",
    "        _doc.metadata[id_key] = _id\n",
    "    sub_docs.extend(_sub_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854d9fb9-824a-41fe-b4b0-f75e49d7b02b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Step 5: Add Documents to Vectorstore\n",
    " Add the smaller chunks and their metadata to the vectorstore for similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b680ec2-0672-43ec-8608-2bd7de1fd2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MultiVectorRetriever</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">vectorstore</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">langchain_chroma.vectorstores.Chroma</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x30d170710</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">byte_store</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;langchain_core.stores.InMemoryByteStore object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x30e3df550</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">docstore</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;langchain.storage.encoder_backed.EncoderBackedStore object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x30d1f28d0</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">search_kwargs</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mMultiVectorRetriever\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mvectorstore\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mlangchain_chroma.vectorstores.Chroma\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x30d170710\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mbyte_store\u001b[0m\u001b[39m=<langchain_core.stores.InMemoryByteStore object at \u001b[0m\u001b[1;36m0x30e3df550\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mdocstore\u001b[0m\u001b[39m=<langchain.storage.encoder_backed.EncoderBackedStore object at \u001b[0m\u001b[1;36m0x30d1f28d0\u001b[0m\u001b[1m>\u001b[0m,\n",
       "    \u001b[33msearch_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retriever.vectorstore.add_documents(sub_docs)\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))\n",
    "print(retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22bb2d2-e1b6-4ee7-aea6-b384ee283c54",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Step 6: Perform a Similarity Search\n",
    " Use the retriever to find documents similar to the query \"LangChain\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59881f72-e3db-4c88-8c5a-56ccae8ffc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'58b2804b-7b53-40ce-97d9-ede3e0852911'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'doc_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'77eeb4f3-f7e8-4df2-a16b-3e63d3978eb2'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data/langchain.md'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LangChain provides a consistent interface for working with chat models from different </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">providers while offering additional features for monitoring, debugging, and optimizing the performance of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">applications that use LLMs.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'97524e7b-902d-4069-a3ce-06f873e0491f'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'doc_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'a5154e19-f37d-4514-aaba-68933f778c71'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data/langchain.md'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LangChain provides a consistent interface for working with chat models from different </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">providers while offering additional features for monitoring, debugging, and optimizing the performance of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">applications that use LLMs.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'58b2804b-7b53-40ce-97d9-ede3e0852911'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'doc_id'\u001b[0m: \u001b[32m'77eeb4f3-f7e8-4df2-a16b-3e63d3978eb2'\u001b[0m, \u001b[32m'source'\u001b[0m: \u001b[32m'data/langchain.md'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'LangChain provides a consistent interface for working with chat models from different \u001b[0m\n",
       "\u001b[32mproviders while offering additional features for monitoring, debugging, and optimizing the performance of \u001b[0m\n",
       "\u001b[32mapplications that use LLMs.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'97524e7b-902d-4069-a3ce-06f873e0491f'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'doc_id'\u001b[0m: \u001b[32m'a5154e19-f37d-4514-aaba-68933f778c71'\u001b[0m, \u001b[32m'source'\u001b[0m: \u001b[32m'data/langchain.md'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'LangChain provides a consistent interface for working with chat models from different \u001b[0m\n",
       "\u001b[32mproviders while offering additional features for monitoring, debugging, and optimizing the performance of \u001b[0m\n",
       "\u001b[32mapplications that use LLMs.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(retriever.vectorstore.similarity_search(\"LangChain\")[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31458ef6-090b-421d-ae81-0779ea1e2f5e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Step 7: Multi-Modal Retrieval\n",
    " Modify the search type to use Maximal Marginal Relevance (MMR) for diverse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69c34d97-635b-403c-9ce3-77316430cd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "retriever.search_type = SearchType.mmr\n",
    "print(retriever.invoke(\"LangChain\")[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3370c4-a402-4a08-932a-7debe40afc32",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Step 8: Summarize Documents\n",
    " Associate summaries with documents using a language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17895d90-4ada-4f78-a4e4-5dfb93025c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'The document provides an overview of LangChain, specifically the concept of large language models (LLMs) and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">their application in a chat model interface. It mentions that LLMs are machine learning models that excel in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">various language-related tasks without requiring task-specific fine-tuning for every scenario. The document </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">highlights the capabilities of modern LLMs, including text generation, translation, summarization, question </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">answering, etc., which can be accessed through a chat model interface.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'The document discusses the advancements in chat models, specifically highlighting the following </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capabilities:\\n\\n1. **Tool calling**: A native API that allows LLMs to interact with external services, APIs, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">databases.\\n2. **Structured output**: The ability of a chat model to respond in a structured format, such as JSON, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">matching a given schema.\\n3. **Multimodality**: Working with data beyond text, including images, audio, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">video.\\n\\nThese features enable developers to build more advanced and complex applications that can handle various </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">types of input and output.'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'The document provides an overview of LangChain, specifically the concept of large language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and \u001b[0m\n",
       "\u001b[32mtheir application in a chat model interface. It mentions that LLMs are machine learning models that excel in \u001b[0m\n",
       "\u001b[32mvarious language-related tasks without requiring task-specific fine-tuning for every scenario. The document \u001b[0m\n",
       "\u001b[32mhighlights the capabilities of modern LLMs, including text generation, translation, summarization, question \u001b[0m\n",
       "\u001b[32manswering, etc., which can be accessed through a chat model interface.'\u001b[0m,\n",
       "    \u001b[32m'The document discusses the advancements in chat models, specifically highlighting the following \u001b[0m\n",
       "\u001b[32mcapabilities:\\n\\n1. **Tool calling**: A native API that allows LLMs to interact with external services, APIs, and \u001b[0m\n",
       "\u001b[32mdatabases.\\n2. **Structured output**: The ability of a chat model to respond in a structured format, such as JSON, \u001b[0m\n",
       "\u001b[32mmatching a given schema.\\n3. **Multimodality**: Working with data beyond text, including images, audio, and \u001b[0m\n",
       "\u001b[32mvideo.\\n\\nThese features enable developers to build more advanced and complex applications that can handle various \u001b[0m\n",
       "\u001b[32mtypes of input and output.'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOllama(model='llama3.2:1b')\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Summarize documents in parallel\n",
    "summaries = chain.batch(docs, {\"max_concurrency\": 5})\n",
    "print(summaries[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09103003-a352-48ad-8e4e-77144b004366",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Step 9: Add Summaries to Vectorstore\n",
    " Store the summaries in the vectorstore for enhanced retrieval capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af8b5863-4267-48ee-9396-cc0968111b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(collection_name=\"summaries\", embedding_function=OpenAIEmbeddings())\n",
    "store = InMemoryByteStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "summary_docs = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries)\n",
    "]\n",
    "\n",
    "retriever.vectorstore.add_documents(summary_docs)\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713fe068-a00d-42ad-9394-d3c0f4ccca03",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## Step 10: Retrieve Summaries\n",
    " Perform a similarity search on the summaries to get the most relevant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52de173c-6bb5-478c-b7f5-41373c930703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sub Docs:\n",
       "\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'810f2212-0166-4293-a9d3-ddf1834072d8'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'doc_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'a5154e19-f37d-4514-aaba-68933f778c71'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The document describes LangChain's features as follows:\\n\\n- Provides a consistent interface for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interacting with various chat models.\\n- Offers additional features such as monitoring, debugging, and optimization</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for improving application performance with Large Language Models (LLMs).\"</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Sub Docs:\n",
       "\n",
       "\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'810f2212-0166-4293-a9d3-ddf1834072d8'\u001b[0m,\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'doc_id'\u001b[0m: \u001b[32m'a5154e19-f37d-4514-aaba-68933f778c71'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mpage_content\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m document describes LangChain's features as follows:\\n\\n- Provides a consistent interface for \u001b[0m\n",
       "\u001b[32minteracting with various chat models.\\n- Offers additional features such as monitoring, debugging, and optimization\u001b[0m\n",
       "\u001b[32mfor improving application performance with Large Language Models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\"\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Retrieved Docs:\n",
       "\n",
       "<span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data/langchain.md'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Features[\\u200b](https://python.langchain.com/docs/concepts/chat_models/#features \"Direct </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">link to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Features\")\\n-------------------------------------------------------------------------------------------------------</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\n\\nLangChain provides a consistent interface for working with chat models from different providers while offering </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">additional features for monitoring, debugging, and optimizing the performance of applications that use LLMs.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Retrieved Docs:\n",
       "\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'data/langchain.md'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Features\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\u200b\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://python.langchain.com/docs/concepts/chat_models/#features \"Direct \u001b[0m\n",
       "\u001b[32mlink to \u001b[0m\n",
       "\u001b[32mFeatures\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n-------------------------------------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[32m\\n\\nLangChain provides a consistent interface for working with chat models from different providers while offering \u001b[0m\n",
       "\u001b[32madditional features for monitoring, debugging, and optimizing the performance of applications that use LLMs.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_docs = retriever.vectorstore.similarity_search(\"LangChain\")\n",
    "print(\"Sub Docs:\\n\",sub_docs[0])\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"LangChain\")\n",
    "print(\"Retrieved Docs:\\n\",retrieved_docs[0:2])\n",
    "# len(retrieved_docs[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
