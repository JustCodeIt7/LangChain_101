{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a22b1cc7",
   "metadata": {},
   "source": [
    "# Vector Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a7717f33e63cd",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "embedding_model = OllamaEmbeddings(model='snowflake-arctic-embed:22m')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Basics of Vector Stores",
   "id": "af518d6486a937d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Initialize with an embedding model\n",
    "vector_store = InMemoryVectorStore(embedding=embedding_model)\n",
    "\n",
    "# Create a document\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "documents = [document_1, document_2]\n",
    "# Add documents\n",
    "vector_store.add_documents(documents=documents)\n",
    "# Add documents with custom IDs\n",
    "vector_store.add_documents(documents=documents, ids=[\"doc1\", \"doc2\"])\n",
    "\n",
    "# Delete documents\n",
    "vector_store.delete(ids=[\"doc1\"])\n",
    "\n",
    "# Search for similar documents\n",
    "query = \"What is the weather forecast for tomorrow?\"\n",
    "results = vector_store.similarity_search(query, k=5)\n",
    "print(results)"
   ],
   "id": "5436e96d705d7860",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2db3a6de9c15bec9",
   "metadata": {},
   "source": [
    "## Embedding Models and Text Loaders"
   ]
  },
  {
   "cell_type": "code",
   "id": "a7e2ec91110583d8",
   "metadata": {},
   "source": [
    "fp = \"data/constitution.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(fp)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "\n",
    "documents = text_splitter.split_documents(docs)\n",
    "print(len(documents))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "750e775417e4b66f",
   "metadata": {},
   "source": "## Vector Store Creation Using Chroma and FAISS"
  },
  {
   "cell_type": "code",
   "id": "b99c3f44f8e33120",
   "metadata": {},
   "source": [
    "################### CHROMA ###################\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "db = Chroma.from_documents(documents, embedding_model, persist_directory=\"./chroma\")\n",
    "\n",
    "################### FAISS ###################\n",
    "from langchain_community.vectorstores import FAISS\n",
    "db = FAISS.from_documents(documents, embedding_model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6ae8381cd0d8a42e",
   "metadata": {},
   "source": [
    "## Similarity search"
   ]
  },
  {
   "cell_type": "code",
   "id": "f4c7622800f93f83",
   "metadata": {},
   "source": [
    "query = \"What is the role of the President of the United States? What are the powers of the President of the United States?\"\n",
    "\n",
    "results = db.similarity_search(query, k=5)\n",
    "\n",
    "results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b5fdc9a9bf3cef50",
   "metadata": {},
   "source": [
    "### Similarity search by vector"
   ]
  },
  {
   "cell_type": "code",
   "id": "55e4456040ff557c",
   "metadata": {},
   "source": [
    "embedding_vector = embedding_model.embed_query(query)\n",
    "docs = db.similarity_search_by_vector(embedding_vector, k=5)\n",
    "\n",
    "docs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f96e8521f0e1b293",
   "metadata": {},
   "source": [
    "## Asynchronous Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "id": "5141ee895b019eb6",
   "metadata": {},
   "source": [
    "docs = await db.asimilarity_search(query)\n",
    "docs\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chat with Vector Store",
   "id": "8de2165119c12741"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOllama(model='llama3.2:1b')"
   ],
   "id": "2c8ca62c1bfec220",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Perform a vector store similarity search\n",
    "context_results = db.similarity_search(query, k=4)\n",
    "\n",
    "# Create a prompt template and fill it with context\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"query\"],\n",
    "    template=\"Based on the following context:\\n{context}\\n\\n{query}\"\n",
    ")\n",
    "\n",
    "# Fill the prompt template with the search results and the query\n",
    "full_prompt = prompt_template.format(\n",
    "    context=\"\\n\".join([doc.page_content for doc in context_results]),\n",
    "    query=query\n",
    ")\n",
    "\n",
    "# Use the language model to generate a response\n",
    "response = llm.invoke(full_prompt)\n",
    "print(response.content)"
   ],
   "id": "a23243501166ab13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5116e34bebc0d860",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
