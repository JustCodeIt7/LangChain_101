{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Expression Language (LCEL)\n",
    "\n",
    "The **L**ang**C**hain **E**xpression **L**anguage (LCEL) abstracts key Python concepts into a streamlined format, facilitating a \"minimalist\" code layer for constructing chains of LangChain components. LCEL offers robust support for:\n",
    "\n",
    "1. Rapid development of chains.\n",
    "2. Advanced features like streaming, asynchronous processing, parallel execution, and more.\n",
    "3. Seamless integration with LangSmith and LangServe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU \\\n",
    "#     langchain==0.0.345 \\\n",
    "#     anthropic==0.7.7 \\\n",
    "#     cohere==4.37 \\\n",
    "#     docarray==0.39.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCEL Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from rich import print as pp\n",
    "\n",
    "# Define a prompt for generating book recommendations\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Suggest some books for the genre {genre}\"\n",
    ")\n",
    "\n",
    "# Use a different model\n",
    "model = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IIn a standard LangChain setup, we would connect these components using an LLMChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some popular and highly-recommended science fiction books across various sub-genres:\n",
      "\n",
      "**Classic Sci-Fi**\n",
      "\n",
      "1. \"Dune\" by Frank Herbert - A seminal work of sci-fi that explores politics, ecology, and human evolution on a desert planet.\n",
      "2. \"Foundation\" by Isaac Asimov - A groundbreaking novel that spans centuries, exploring the rise and fall of an interstellar empire.\n",
      "3. \"2001: A Space Odyssey\" by Arthur C. Clarke - A thought-provoking novel that explores the intersection of humanity and technology.\n",
      "\n",
      "**Space Opera**\n",
      "\n",
      "1. \"The Three-Body Problem\" by Liu Cixin - A award-winning novel that explores the first contact between humans and an alien civilization.\n",
      "2. \"Old Man's War\" by John Scalzi - A fun, action-packed novel that explores the human condition through space travel and colonization.\n",
      "3. \"A Closed and Common Orbit\" by Becky Chambers - A character-driven novel that explores identity, community, and acceptance in a sci-fi universe.\n",
      "\n",
      "**Dystopian Sci-Fi**\n",
      "\n",
      "1. \"The Handmaid's Tale\" by Margaret Atwood - A classic dystopian novel that explores a patriarchal society where women have lost all their rights.\n",
      "2. \"Fahrenheit 451\" by Ray Bradbury - A powerful warning about censorship, conformity, and the dangers of a society that rejects knowledge.\n",
      "3. \"Station Eleven\" by Emily St. John Mandel - A beautifully written novel that weaves together multiple storylines set before and after a flu pandemic that wipes out most of humanity.\n",
      "\n",
      "**Cyberpunk**\n",
      "\n",
      "1. \"Neuromancer\" by William Gibson - A groundbreaking novel that explores the intersection of artificial intelligence, virtual reality, and corporate power.\n",
      "2. \"Synners\" by Pat Cadigan - A classic cyberpunk novel that delves into the world of virtual reality and its impact on society.\n",
      "3. \"Altered Carbon\" by Richard K. Morgan - A gritty, noir-inspired novel that explores the implications of human consciousness in a world where bodies can be easily replaced.\n",
      "\n",
      "**Time Travel**\n",
      "\n",
      "1. \"Slaughterhouse-Five\" by Kurt Vonnegut - A classic anti-war novel that explores the concept of time and its relationship to human experience.\n",
      "2. \"The Time Machine\" by H.G. Wells - A foundational work of science fiction that explores the concept of time travel and social commentary.\n",
      "3. \"11/22/63\" by Stephen King - A thought-provoking novel that explores the consequences of altering historical events.\n",
      "\n",
      "**Biopunk**\n",
      "\n",
      "1. \"Oryx and Crake\" by Margaret Atwood - A dystopian novel that explores a world ravaged by climate change, biotechnology gone wrong, and humanity's last hope.\n",
      "2. \"The Girl with All the Gifts\" by M.R. Carey - A thrilling novel that combines elements of sci-fi, horror, and adventure to explore a post-apocalyptic world.\n",
      "3. \"Station Eleven\" by Emily St. John Mandel (also mentioned earlier) also contains biopunk themes.\n",
      "\n",
      "**Soft Sci-Fi**\n",
      "\n",
      "1. \"The Martian\" by Andy Weir - A gripping survival story that explores the challenges of being stranded on Mars with limited resources.\n",
      "2. \"Ready Player One\" by Ernest Cline - A fun, nostalgia-fueled novel that explores a future where virtual reality has become indistinguishable from reality.\n",
      "3. \"The Long Way to a Small, Angry Planet\" by Becky Chambers (also mentioned earlier) is a character-driven novel that explores the complexities of human relationships in a sci-fi universe.\n",
      "\n",
      "These are just a few examples of the many amazing science fiction books out there. Is there a specific sub-genre or theme you'd like me to focus on?\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Create a chain for book recommendations\n",
    "chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=model,\n",
    "    output_parser=output_parser\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "out = chain.run(genre=\"Science Fiction\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using LCEL the format is different, rather than relying on `Chains` we simple chain together each component using the pipe operator `|`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some popular and highly-recommended science fiction books across various sub-genres:\n",
      "\n",
      "**Classic Science Fiction**\n",
      "\n",
      "1. \"Dune\" by Frank Herbert - A seminal work of epic science fiction set in a desert planet where humans have colonized.\n",
      "2. \"Foundation\" by Isaac Asimov - A classic novel that explores the concept of psychohistory and the fate of humanity.\n",
      "3. \"1984\" by George Orwell - A dystopian novel that depicts a totalitarian future society.\n",
      "\n",
      "**Space Opera**\n",
      "\n",
      "1. \"The Three-Body Problem\" by Liu Cixin - A award-winning novel that explores the first contact between humans and an alien civilization.\n",
      "2. \"Old Man's War\" by John Scalzi - A fun and action-packed novel about a group of seniors who join the military to fight in an intergalactic war.\n",
      "3. \"The Expanse\" series by James S. A. Corey - A gritty and realistic series set in a future where humanity has colonized the solar system.\n",
      "\n",
      "**Cyberpunk**\n",
      "\n",
      "1. \"Neuromancer\" by William Gibson - A groundbreaking novel that explores the intersection of artificial intelligence, virtual reality, and human consciousness.\n",
      "2. \"Snow Crash\" by Neal Stephenson - A fast-paced and humorous novel about a pizza delivery driver who becomes embroiled in a plot to disrupt the global network.\n",
      "3. \"Synners\" by Pat Cadigan - A thought-provoking novel that explores the impact of virtual reality on society.\n",
      "\n",
      "**Dystopian**\n",
      "\n",
      "1. \"The Handmaid's Tale\" by Margaret Atwood - A classic novel about a future where women have lost all their rights and are forced into reproductive servitude.\n",
      "2. \"Fahrenheit 451\" by Ray Bradbury - A classic novel about a future where books are banned and critical thinking is discouraged.\n",
      "3. \"The Power\" by Naomi Alderman - A thought-provoking novel that explores a world where women suddenly develop the ability to release electrical jolts from their fingertips.\n",
      "\n",
      "**Time Travel**\n",
      "\n",
      "1. \"The Time Machine\" by H.G. Wells - A classic novella about a time traveler who journeys to the year 802,701 and discovers a future world divided between the peaceful Eloi and the monstrous Morlocks.\n",
      "2. \"Slaughterhouse-Five\" by Kurt Vonnegut - A novel that explores the experiences of an American soldier during World War II and his subsequent journey through time.\n",
      "3. \"The Time Traveler's Wife\" by Audrey Niffenegger - A romantic novel about a man with a genetic disorder that causes him to time-travel unpredictably.\n",
      "\n",
      "**Science Fiction Comedy**\n",
      "\n",
      "1. \"To Say Nothing of the Dog\" by Connie Willis - A comedic novel about a historian who travels back in time and becomes stuck in the past.\n",
      "2. \"Good Omens\" by Terry Pratchett and Neil Gaiman - A humorous novel about an angel and a demon who join forces to prevent the apocalypse.\n",
      "3. \"Red Dwarf\" by Grant Naylor (Robert Llewellyn) - A comedic series about the misadventures of the last human alive and a hologram of his dead bunkmate on a mining spaceship.\n",
      "\n",
      "These are just a few examples, and there are many more amazing science fiction books out there. Is there a specific sub-genre or theme you're interested in?\n"
     ]
    }
   ],
   "source": [
    "lcel_chain = prompt | model | output_parser\n",
    "\n",
    "# Run the chain\n",
    "out = lcel_chain.invoke({\"genre\": \"Science Fiction\"})\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the Pipe Operator Works\n",
    "To truly grasp LCEL, let's examine how the pipe operation functions. It takes output from the **right** and feeds it to the **left**—but since this isn't standard Python, how is it implemented? We can create our own version using simple functions.\n",
    "\n",
    "We'll utilize the `__or__` method in Python class objects. When we combine two classes like `chain = class_a | class_b`, the Python interpreter checks for the presence of the `__or__` method in these classes. If it exists, the expression `|` is translated to `chain = class_a.__or__(class_b)`. \n",
    "\n",
    "This means both of the following patterns yield the same result:\n",
    "\n",
    "```python\n",
    "# Object approach\n",
    "chain = class_a.__or__(class_b)\n",
    "chain(\"some input\")\n",
    "\n",
    "# Pipe approach\n",
    "chain = class_a | class_b\n",
    "chain(\"some input\")\n",
    "```\n",
    "\n",
    "With this understanding, we can create a `Runnable` class that takes a function and transforms it into a chainable function using the pipe operator `|`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runnable:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def __or__(self, other):\n",
    "        def chained_func(*args, **kwargs):\n",
    "            return other(self.func(*args, **kwargs))\n",
    "        return Runnable(chained_func)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def subtract_three(x):\n",
    "    return x - 3\n",
    "\n",
    "def divide_by_two(x):\n",
    "    return x / 2\n",
    "\n",
    "subtract_three = Runnable(subtract_three)\n",
    "divide_by_two = Runnable(divide_by_two)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `__or__` directly we get the correct answer, now let's try using the pipe operator `|` to chain them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chain = subtract_three | divide_by_two\n",
    "print(chain(10))  # Output: 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using either method we get the same response, at it's core this is what LCEL is doing, but there is more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCEL Deep Dive\n",
    "Now that we understand what this syntax is doing under the hood, let's explore it within the context of LCEL and see a few of the additional methods that LangChain has provided to maximize flexibility when working with LCEL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runnables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with LCEL we may find that we need to modify the structure or values being passed between components — for this we can use _runnables_. Let's try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# Create an embedding model\n",
    "embedding = OllamaEmbeddings(model=\"snowflake-arctic-embed:33m\")\n",
    "\n",
    "# Create two vector stores with different texts\n",
    "vecstore_a = InMemoryVectorStore.from_texts(\n",
    "    [\"Python is a popular programming language\", \"Python is used for web development\"],\n",
    "    embedding=embedding\n",
    ")\n",
    "vecstore_b = InMemoryVectorStore.from_texts(\n",
    "    [\"Python is great for data science\", \"Python is known for its simplicity\"],\n",
    "    embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating retrievers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.runnables import (\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough\n",
    ")\n",
    "\n",
    "retriever_a = vecstore_a.as_retriever()\n",
    "retriever_b = vecstore_b.as_retriever()\n",
    "\n",
    "prompt_str = \"\"\"Answer the following questions about Python:\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_str)\n",
    "\n",
    "retriever = RunnableParallel(\n",
    "    {'context': retriever_a, 'question': RunnablePassthrough()},\n",
    ")\n",
    "\n",
    "chain = retriever | prompt | model | output_parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context, Python is used for web development.\n"
     ]
    }
   ],
   "source": [
    "out = chain.invoke(\"What is Python used for?\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have used `RunnableParallel` to create two parallel streams of information, one for `\"context\"` that is information fed in from `retriever_a`, and another for `\"question\"` which is the _passthrough_ information, ie the information that is passed through from our `chain.invoke(\"when was James born?\")` call.\n",
    "\n",
    "Using this information the chain is close to answering the question but it doesn't have enough information, it is missing the information that we have stored in `retriever_b`. Fortunately, we can have multiple parallel information streams using the `RunnableParallel` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_str = \"\"\"Answer the question below using the context:\n",
    "\n",
    "Context:\n",
    "{context_a}\n",
    "{context_b}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_str)\n",
    "\n",
    "retrieval = RunnableParallel(\n",
    "    {\n",
    "        \"context_a\": retriever_a, \"context_b\": retriever_b,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    ")\n",
    "\n",
    "chain = retrieval | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context, Python is used for web development.\n"
     ]
    }
   ],
   "source": [
    "ut = chain.invoke(\"Why is Python popular?\")\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable Lambdas\n",
    "The `RunnableLambda` is a LangChain abstraction that allows us to turn Python functions into pipe-compatible function, similar to the `Runnable` class we created near the beginning of this notebook.\n",
    "\n",
    "Let's try it out with our earlier `add_five` and `multiply_by_two` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cube(x):\n",
    "    return x ** 3\n",
    "\n",
    "def calc_reciprocal(x):\n",
    "    return 1 / x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Wrap the functions with RunnableLambda\n",
    "calc_cube = RunnableLambda(calc_cube)\n",
    "calc_reciprocal = RunnableLambda(calc_reciprocal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with our earlier `Runnable` abstraction, we can use `|` operators to chain together our `RunnableLambda` abstractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n"
     ]
    }
   ],
   "source": [
    "chain = calc_cube | calc_reciprocal\n",
    "print(chain.invoke(2))  # Output: 0.1chain = calc_cube | calc_reciprocal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike our `Runnable` abstraction, we cannot run the `RunnableLambda` chain by calling it directly, instead we must call `chain.invoke`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037037037037037035"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can see the same answer. Naturally we can feed custom functions into our chains using this approach. Let's try a short chain and see where we might want to insert a custom function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rompt_str = \"\"\"Tell me a fun fact about {animal}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_str)\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'context_b', 'question', 'context_a'}.  Expected: ['context_a', 'context_b', 'question'] Received: ['animal']\\nNote: if you intended {context_b} to be part of the string and not a variable, please escape it with double curly braces like: '{{context_b}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pp(chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manimal\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melephants\u001b[39m\u001b[38;5;124m\"\u001b[39m}))\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/runnables/base.py:3020\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3018\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3020\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3021\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/prompts/base.py:208\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[1;32m    207\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_prompt_with_error_handling,\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    211\u001b[0m     config,\n\u001b[1;32m    212\u001b[0m     run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    213\u001b[0m     serialized\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m    214\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/runnables/base.py:1925\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1921\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1922\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1923\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1924\u001b[0m         Output,\n\u001b[0;32m-> 1925\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m   1926\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1927\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1928\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1929\u001b[0m             config,\n\u001b[1;32m   1930\u001b[0m             run_manager,\n\u001b[1;32m   1931\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1932\u001b[0m         ),\n\u001b[1;32m   1933\u001b[0m     )\n\u001b[1;32m   1934\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1935\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/runnables/config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/prompts/base.py:182\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[0;32m--> 182\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(inner_input)\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/prompts/base.py:176\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    170\u001b[0m     example_key \u001b[38;5;241m=\u001b[39m missing\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    171\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m to be part of the string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m     )\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    177\u001b[0m         create_message(message\u001b[38;5;241m=\u001b[39mmsg, error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mINVALID_PROMPT_INPUT)\n\u001b[1;32m    178\u001b[0m     )\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Input to ChatPromptTemplate is missing variables {'context_b', 'question', 'context_a'}.  Expected: ['context_a', 'context_b', 'question'] Received: ['animal']\\nNote: if you intended {context_b} to be part of the string and not a variable, please escape it with double curly braces like: '{{context_b}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "pp(chain.invoke({\"animal\": \"elephants\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'context_b', 'question', 'context_a'}.  Expected: ['context_a', 'context_b', 'question'] Received: ['topic']\\nNote: if you intended {context_b} to be part of the string and not a variable, please escape it with double curly braces like: '{{context_b}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pp(chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArtificial Intelligence\u001b[39m\u001b[38;5;124m\"\u001b[39m}))\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/runnables/base.py:3020\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3018\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3020\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3021\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/prompts/base.py:208\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[1;32m    207\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_prompt_with_error_handling,\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    211\u001b[0m     config,\n\u001b[1;32m    212\u001b[0m     run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    213\u001b[0m     serialized\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m    214\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/runnables/base.py:1925\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1921\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1922\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1923\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1924\u001b[0m         Output,\n\u001b[0;32m-> 1925\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m   1926\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1927\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1928\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1929\u001b[0m             config,\n\u001b[1;32m   1930\u001b[0m             run_manager,\n\u001b[1;32m   1931\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1932\u001b[0m         ),\n\u001b[1;32m   1933\u001b[0m     )\n\u001b[1;32m   1934\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1935\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/runnables/config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/prompts/base.py:182\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[0;32m--> 182\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(inner_input)\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/prompts/base.py:176\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    170\u001b[0m     example_key \u001b[38;5;241m=\u001b[39m missing\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    171\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m to be part of the string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m     )\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    177\u001b[0m         create_message(message\u001b[38;5;241m=\u001b[39mmsg, error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mINVALID_PROMPT_INPUT)\n\u001b[1;32m    178\u001b[0m     )\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Input to ChatPromptTemplate is missing variables {'context_b', 'question', 'context_a'}.  Expected: ['context_a', 'context_b', 'question'] Received: ['topic']\\nNote: if you intended {context_b} to be part of the string and not a variable, please escape it with double curly braces like: '{{context_b}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "pp(chain.invoke({\"topic\": \"Artificial Intelligence\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned text always includes the initial `\"Here's a short fact about ...\\n\\n\"` — let's add a function to split on double newlines `\"\\n\\n\"` and only return the fact itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'context_b', 'question', 'context_a'}.  Expected: ['context_a', 'context_b', 'question'] Received: ['animal']\\nNote: if you intended {context_b} to be part of the string and not a variable, please escape it with double curly braces like: '{{context_b}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m get_fun_fact \u001b[38;5;241m=\u001b[39m RunnableLambda(extract_fun_fact)\n\u001b[1;32m     10\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m model \u001b[38;5;241m|\u001b[39m output_parser \u001b[38;5;241m|\u001b[39m get_fun_fact\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manimal\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDolphins\u001b[39m\u001b[38;5;124m\"\u001b[39m}))\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/runnables/base.py:3020\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3018\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3020\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3021\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/prompts/base.py:208\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[1;32m    207\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_prompt_with_error_handling,\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    211\u001b[0m     config,\n\u001b[1;32m    212\u001b[0m     run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    213\u001b[0m     serialized\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m    214\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/runnables/base.py:1925\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1921\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1922\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1923\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1924\u001b[0m         Output,\n\u001b[0;32m-> 1925\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m   1926\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1927\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1928\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1929\u001b[0m             config,\n\u001b[1;32m   1930\u001b[0m             run_manager,\n\u001b[1;32m   1931\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1932\u001b[0m         ),\n\u001b[1;32m   1933\u001b[0m     )\n\u001b[1;32m   1934\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1935\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/runnables/config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/prompts/base.py:182\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[0;32m--> 182\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(inner_input)\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm311/lib/python3.11/site-packages/langchain_core/prompts/base.py:176\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    170\u001b[0m     example_key \u001b[38;5;241m=\u001b[39m missing\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    171\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m to be part of the string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m     )\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    177\u001b[0m         create_message(message\u001b[38;5;241m=\u001b[39mmsg, error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mINVALID_PROMPT_INPUT)\n\u001b[1;32m    178\u001b[0m     )\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Input to ChatPromptTemplate is missing variables {'context_b', 'question', 'context_a'}.  Expected: ['context_a', 'context_b', 'question'] Received: ['animal']\\nNote: if you intended {context_b} to be part of the string and not a variable, please escape it with double curly braces like: '{{context_b}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "def extract_fact(x):\n",
    "    if \"\\n\\n\" in x:\n",
    "        return \"\\n\".join(x.split(\"\\n\\n\")[1:])\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "get_fact = RunnableLambda(extract_fact)\n",
    "\n",
    "chain = prompt | model | output_parser | get_fact\n",
    "pp(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The term <span style=\"color: #008000; text-decoration-color: #008000\">\"Artificial Intelligence\"</span> <span style=\"font-weight: bold\">(</span>AI<span style=\"font-weight: bold\">)</span> was first coined in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1956</span> by John McCarthy, who used it to describe the goal\n",
       "of creating machines that could simulate human intelligence and think like humans.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The term \u001b[32m\"Artificial Intelligence\"\u001b[0m \u001b[1m(\u001b[0mAI\u001b[1m)\u001b[0m was first coined in \u001b[1;36m1956\u001b[0m by John McCarthy, who used it to describe the goal\n",
       "of creating machines that could simulate human intelligence and think like humans.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pp(chain.invoke({\"topic\": \"Artificial Intelligence\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Did you know that the first AI program, called <span style=\"color: #008000; text-decoration-color: #008000\">\"Logical Theorist,\"</span> was developed in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1956</span> by Allen Newell and \n",
       "Herbert Simon? This groundbreaking program could reason and solve problems using logical rules, marking the \n",
       "beginning of the field of Artificial Intelligence as we know it today.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Did you know that the first AI program, called \u001b[32m\"Logical Theorist,\"\u001b[0m was developed in \u001b[1;36m1956\u001b[0m by Allen Newell and \n",
       "Herbert Simon? This groundbreaking program could reason and solve problems using logical rules, marking the \n",
       "beginning of the field of Artificial Intelligence as we know it today.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pp(chain.invoke({\"topic\": \"Artificial Intelligence\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're getting well formatted outputs using our final custom `get_fact` function.\n",
    "\n",
    "---\n",
    "\n",
    "That covers the essentials you need to getting started and building with the **L**ang**C**hain **E**xpression **L**anguage (LCEL). With it, we can put together chains very easily — and the current focus of the LangChain team is on further LCEL development and support.\n",
    "\n",
    "The pros and cons of LCEL are varied. Those that love it tend to focus on the minimalist code style, LCEL's support for streaming, parallel operations, and async, and LCEL's nice integration with LangChain's focus on chaining components together.\n",
    "\n",
    "There are also people that are less fond of LCEL. Typically people will point to it being yet another abstraction on top of an already very abstract library, that the syntax is confusing, against [the Zen of Python](https://peps.python.org/pep-0020/), and requires too much effort to learn new (or uncommon) syntax.\n",
    "\n",
    "Both viewpoints are entirely valid, LCEL is a very different approach — ofcourse there are major pros and major cons. In either case, if you're willing to spend some time learning the syntax, it allows us to develop very quickly, and with that in mind it's well worth learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
